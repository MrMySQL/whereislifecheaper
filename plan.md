# Implementation Plan: WhereIsLifeCheaper - Grocery Price Comparison System

## Project Overview

Build a web scraping system to compare grocery basket prices across **Turkey, Montenegro, Spain, and Uzbekistan** by automatically scraping supermarket websites daily and storing price data in a PostgreSQL database with a simple dashboard for visualization.

### Tech Stack
- **Backend**: Node.js + TypeScript + Express.js
- **Scraping**: Playwright for browser automation
- **Database**: PostgreSQL 15+
- **Scheduling**: node-cron for daily automation
- **Frontend**: React + Vite for simple dashboard
- **Logging**: Winston

## Architecture Summary

### Core Components
1. **Scraper Service**: Modular scrapers for each supermarket using Playwright
2. **Database Layer**: PostgreSQL with comprehensive schema for products, prices, countries, supermarkets
3. **API Service**: Express REST API for frontend data access
4. **Scheduler**: Daily cronjob to trigger scrapers for all supermarkets
5. **Frontend Dashboard**: Simple React app for price comparisons

### Key Design Decisions
- **Modular Scraper Architecture**: Abstract `BaseScraper` class extended by country-specific scrapers
- **Product Matching**: Use normalized names, brands, units, and barcodes to match products across countries
- **Price History**: Store all price points with timestamps for trend analysis
- **Error Resilience**: Retry logic, comprehensive logging, scrape status tracking

## Project Structure

```
whereislifecheaper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ BaseScraper.ts          # Abstract scraper class
â”‚   â”‚   â”‚   â””â”€â”€ ScraperFactory.ts       # Factory pattern
â”‚   â”‚   â”œâ”€â”€ turkey/                     # Migros, A101, BIM, ÅžOK, CarrefourSA
â”‚   â”‚   â”œâ”€â”€ montenegro/                 # Voli, Idea, HDL
â”‚   â”‚   â”œâ”€â”€ spain/                      # Mercadona, Carrefour, Alcampo, Dia
â”‚   â”‚   â””â”€â”€ uzbekistan/                 # Korzinka, Makro, Havas
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ migrations/                 # SQL migration files
â”‚   â”‚   â””â”€â”€ models/                     # Database models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ scraper.service.ts          # Orchestrates scraping
â”‚   â”‚   â”œâ”€â”€ product.service.ts          # Product matching
â”‚   â”‚   â””â”€â”€ price.service.ts            # Price management
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/                     # Express routes
â”‚   â”‚   â””â”€â”€ controllers/                # Request handlers
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â”œâ”€â”€ cron.ts                     # Cron job setup
â”‚   â”‚   â””â”€â”€ jobs/dailyScrape.job.ts     # Daily scraping job
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.ts                   # Winston logger
â”‚   â”‚   â”œâ”€â”€ normalizer.ts               # Product name normalization
â”‚   â”‚   â””â”€â”€ retry.ts                    # Retry logic
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ database.ts                 # DB connection
â”‚       â””â”€â”€ scrapers.ts                 # Scraper configs
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/                 # React components
â”‚       â””â”€â”€ services/api.service.ts     # API client
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ migrate.ts                      # Run migrations
â”‚   â””â”€â”€ seed.ts                         # Seed initial data
â””â”€â”€ logs/                               # Application logs
```

## Database Schema

### Core Tables

**countries**
- Stores Turkey, Montenegro, Spain, Uzbekistan with currency codes

**supermarkets**
- Links to country, stores website URL, scraper class name, config

**categories**
- Product categories (Fruits & Vegetables, Dairy, Meat, etc.)

**products**
- Product name, normalized_name (for matching), brand, unit, unit_quantity, barcode
- product_group_id for cross-country matching

**product_mappings**
- Links products to supermarkets with external_id and URL
- Tracks last_scraped_at and availability

**prices**
- Historical price data with timestamps
- Links to product_mapping, stores price, currency, is_on_sale, price_per_unit

**scrape_logs**
- Tracks each scraping run with status, duration, products_scraped, errors

### Key Indexes
- `products.normalized_name` - Fast product matching
- `prices.product_mapping_id + scraped_at` - Efficient price history queries
- `product_mappings.supermarket_id` - Quick supermarket product lookups

## Target Supermarkets

### Turkey
- **Migros** (migros.com.tr) - START HERE
- A101, BIM, ÅžOK, CarrefourSA

### Montenegro
- **Voli** (voli.me)
- Idea, HDL Market

### Spain
- **Mercadona** (mercadona.es)
- Carrefour, Alcampo, Dia

### Uzbekistan
- **Korzinka** (korzinka.uz)
- Makro, Havas

## Implementation Steps

### Phase 1: Foundation âœ… COMPLETED
1. **Project Setup** âœ…
   - âœ… Initialize package.json with TypeScript, Express, Playwright, pg, node-cron, winston
   - âœ… Create directory structure
   - âœ… Setup tsconfig.json
   - âœ… Create .env with database credentials
   - âœ… Create .gitignore and README.md

2. **Database Setup** âœ…
   - âœ… Create docker-compose.yml for PostgreSQL
   - âœ… Write migration files for all tables (6 migrations)
   - âœ… Create seed data for countries, initial supermarkets, common categories
   - âœ… Setup database connection module
   - âœ… Create migration and seed scripts

3. **Configuration** âœ…
   - âœ… Create environment variable validation (config/env.ts)
   - âœ… Setup Winston logger with file and console transports
   - âœ… Create database connection pool with DATABASE_URL
   - âœ… Create type definitions (scraper.types.ts, product.types.ts, api.types.ts)
   - âœ… Create utility modules (normalizer.ts, retry.ts)

### Phase 2: Scraper Foundation âœ… COMPLETED
1. **Base Scraper Architecture** âœ…
   - âœ… Implement `BaseScraper` abstract class with:
     - âœ… `initialize()` - Setup Playwright browser/page
     - âœ… `scrapeProductList()` - Get all products from category pages
     - âœ… `scrapeProductDetails(url)` - Get detailed product info
     - âœ… `cleanup()` - Close browser
     - âœ… Common retry logic, anti-bot handling, screenshot on error
     - âœ… Helper methods for element extraction, navigation, waiting

2. **Scraper Factory** âœ…
   - âœ… Create factory pattern to instantiate correct scraper based on supermarket
   - âœ… Support for database-driven configuration

3. **First Scraper: Migros Turkey** âœ…
   - âœ… Create `MigrosScraper` extending `BaseScraper`
   - âœ… Implement selectors configuration for Migros
   - âœ… Implement product list scraping with pagination
   - âœ… Implement product card extraction
   - âœ… Integrate data normalization utilities
   - âœ… Create test script for manual scraper testing

### Phase 3: Data Services âœ… COMPLETED
1. **Product Normalization** âœ…
   - âœ… Create `normalizeProductName()` to standardize product names
   - âœ… Create `extractQuantity()` to parse "1.5L", "500g", etc.
   - âœ… Implement brand extraction logic

2. **Product Matching Service** âœ…
   - âœ… Implement matching algorithm:
     1. Match by barcode (if available)
     2. Match by brand + normalized_name + unit
     3. Fuzzy matching within category
   - âœ… Create product groups for equivalent products
   - âœ… ProductService with findOrCreateProduct, recordPrice methods

3. **Scraper Service** âœ…
   - âœ… Orchestrate scraping: initialize scraper â†’ scrape â†’ save to DB â†’ log results
   - âœ… Handle transactions for data consistency
   - âœ… Implement error handling and logging
   - âœ… Incremental saving after each page (onPageScraped callback)

### Phase 4: Scheduler âœ… COMPLETED
1. **Daily Scrape Job** âœ…
   - âœ… Create `dailyScrape.job.ts`:
     - Get all active supermarkets
     - For each supermarket: create scraper, scrape, save prices, log status
     - Add delays between supermarkets to avoid rate limiting

2. **Cron Setup** âœ…
   - âœ… Configure node-cron to run daily at 2 AM UTC
   - âœ… Create manual trigger endpoint for testing

3. **Testing** âœ…
   - âœ… Test scraping job manually
   - âœ… Verify data saved correctly in database
   - âœ… Check logging output

### Phase 5: API Development âœ… COMPLETED
1. **Express Server Setup** âœ…
   - âœ… Initialize Express with middleware: CORS, helmet, body-parser, error handler
   - âœ… Setup route structure

2. **Core Endpoints** âœ…
   ```
   GET /api/countries                     # List countries âœ…
   GET /api/supermarkets                  # List supermarkets âœ…
   GET /api/products?category=...         # List products with filters âœ…
   GET /api/products/:id                  # Product details âœ…
   GET /api/prices/latest?product_ids=... # Latest prices âœ…
   GET /api/prices/history/:productId     # Price history âœ…
   GET /api/canonical                     # Canonical products for matching âœ…
   GET /api/canonical/comparison          # Cross-country price comparison âœ…
   GET /api/canonical/products-by-country # Products by country âœ…
   PUT /api/canonical/link                # Link product to canonical âœ…
   ```

3. **Controllers & Services** âœ…
   - âœ… Implement controllers for each route
   - âœ… Create services for data access (ProductService, PriceService)

### Phase 6: Frontend Dashboard âœ… COMPLETED
1. **Simple HTML Dashboard** âœ… (Using vanilla JS instead of React for simplicity)
   - âœ… public/index.html - Main dashboard with scraper stats
   - âœ… public/mapping.html - Product mapping UI for canonical products
   - âœ… Product images display (50x50)
   - âœ… Search and filter functionality

2. **Core Features** âœ…
   - âœ… Country selector
   - âœ… Product list with search
   - âœ… Product-to-canonical mapping interface
   - âœ… Scraper status dashboard

### Phase 7: Additional Scrapers âœ… PARTIALLY COMPLETED
1. **Turkey - Migros** âœ…
   - âœ… MigrosScraper using REST API (faster than HTML scraping)
   - âœ… Cloudflare bypass using Playwright browser context
   - âœ… All food categories configured

2. **Montenegro - Voli** âœ…
   - âœ… VoliScraper implemented
   - âœ… 150+ leaf categories collected (excluding alcohol and pork)
   - âœ… Full category hierarchy: drinks, dairy, fruits, vegetables, meat, fish, snacks, etc.

3. **Spain - Mercadona** ðŸ”„ TODO
   - Config placeholder exists
   - Scraper not yet implemented

4. **Uzbekistan - Korzinka** ðŸ”„ TODO
   - Config placeholder exists
   - Scraper not yet implemented

5. **Product Matching Across Countries** ðŸ”„ IN PROGRESS
   - âœ… Canonical products table for manual matching
   - âœ… UI for linking products to canonical products
   - ðŸ”„ Need more products linked to enable cross-country comparison

### Phase 8: Testing & Refinement ðŸ”„ IN PROGRESS
1. **Testing** ðŸ”„
   - ðŸ”„ Unit tests for scrapers (test parsing logic)
   - ðŸ”„ Integration tests for API endpoints
   - âœ… Test cronjob execution
   - âœ… End-to-end test: scrape â†’ store â†’ display in dashboard

2. **Optimization** âœ…
   - âœ… Add database indexes for slow queries
   - âœ… Implement connection pooling
   - ðŸ”„ Add basic caching for frequently accessed data

3. **Monitoring** ðŸ”„
   - âœ… Create health check endpoint
   - ðŸ”„ Setup email alerts for scraper failures
   - âœ… Create admin dashboard to view scrape logs

### Recent Bug Fixes & Improvements
- âœ… Fixed ProductService to use scraper's externalId instead of extracting from URL
- âœ… Fixed extractExternalId regex to handle hex IDs (e.g., `-p-f4725a`)
- âœ… Added product images to mapping page (50x50 with lazy loading)
- âœ… MigrosScraper rewritten to use REST API for efficiency
- âœ… Removed 5-page limit from Migros scraper
- âœ… Added incremental product saving after each page
- âœ… Category filtering for scrapers

## Critical Files to Create (in order)

### 1. Database Schema
`src/database/migrations/001_create_countries.sql` through `006_create_scrape_logs.sql`
- Foundation for all data storage

### 2. Base Scraper
`src/scrapers/base/BaseScraper.ts`
- Abstract class defining scraper interface and common functionality

### 3. Scraper Configuration
`src/config/scrapers.ts`
- Configuration structure for each supermarket's selectors and settings

### 4. First Scraper
`src/scrapers/turkey/MigrosScraper.ts`
- Concrete implementation for Migros Turkey

### 5. Scraper Service
`src/services/scraper.service.ts`
- Orchestrates scraping: scraper â†’ data extraction â†’ database storage â†’ logging

### 6. Daily Scrape Job
`src/scheduler/jobs/dailyScrape.job.ts`
- Automation logic to run all scrapers daily

### 7. Product Service
`src/services/product.service.ts`
- Product matching and normalization logic

### 8. API Server
`src/api/server.ts`
- Express server with routes for frontend

## Key Implementation Details

### Product Normalization Strategy
```typescript
function normalizeProductName(name: string): string {
  return name
    .toLowerCase()
    .replace(/[^a-z0-9\s]/g, '')  // Remove special characters
    .replace(/\s+/g, ' ')          // Normalize whitespace
    .trim();
}

// "Coca-ColaÂ® 1.5L PET" â†’ "cocacola 15l pet"
```

### Product Matching Algorithm
1. **Exact barcode match** (highest confidence)
2. **Brand + normalized_name + unit match** (high confidence)
3. **Fuzzy match within same category** (medium confidence)
4. **Manual mapping table** for common products

### Scraper Configuration Example
```typescript
const migrosConfig = {
  supermarketId: 1,
  name: 'Migros',
  baseUrl: 'https://www.migros.com.tr',
  categoryUrls: ['/meyve-sebze-c-2', '/sut-kahvaltilik-c-4'],
  selectors: {
    productCard: '.product-card',
    productName: '.product-name',
    productPrice: '.product-price',
    productImage: '.product-image img',
    productUrl: '.product-card a'
  },
  waitTimes: {
    pageLoad: 5000,
    dynamicContent: 2000,
    betweenRequests: 1000
  }
};
```

### Daily Scrape Job Flow
```typescript
async function runDailyScrape() {
  const supermarkets = await getActiveSupermarkets();

  for (const supermarket of supermarkets) {
    const logId = await createScrapeLog(supermarket.id);

    try {
      const scraper = ScraperFactory.create(supermarket);
      await scraper.initialize();

      const products = await scraper.scrapeProductList();
      await saveProducts(products, supermarket.id);

      await updateScrapeLog(logId, { status: 'success', count: products.length });
    } catch (error) {
      await updateScrapeLog(logId, { status: 'failed', error: error.message });
      await sendAlert(supermarket.id, error);
    } finally {
      await scraper.cleanup();
    }

    await sleep(60000); // 1 minute delay between supermarkets
  }
}
```

### Error Handling Strategy
- **Network errors**: Retry 3 times with exponential backoff
- **Selector not found**: Log error with screenshot, skip product, continue
- **Anti-bot detection**: Rotate user agents, add random delays
- **Database errors**: Rollback transaction, retry once
- **Critical failures**: Send email alert, log to error log file

## Environment Variables

```env
# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/whereislifecheaper

# API
API_PORT=3000
NODE_ENV=development

# Scraper
PLAYWRIGHT_HEADLESS=true
SCRAPER_MAX_RETRIES=3
SCRAPER_TIMEOUT=30000

# Logging
LOG_LEVEL=info
LOG_DIR=./logs

# Frontend
VITE_API_URL=http://localhost:3000/api
```

## Dependencies

### Backend (package.json)
```json
{
  "dependencies": {
    "express": "^4.18.2",
    "playwright": "^1.40.0",
    "pg": "^8.11.3",
    "node-cron": "^3.0.3",
    "winston": "^3.11.0",
    "dotenv": "^16.3.1",
    "joi": "^17.11.0",
    "cors": "^2.8.5",
    "helmet": "^7.1.0"
  },
  "devDependencies": {
    "@types/node": "^20.10.5",
    "@types/express": "^4.17.21",
    "typescript": "^5.3.3",
    "ts-node": "^10.9.2"
  }
}
```

### Frontend (frontend/package.json)
```json
{
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.21.0",
    "recharts": "^2.10.3",
    "axios": "^1.6.2"
  },
  "devDependencies": {
    "@vitejs/plugin-react": "^4.2.1",
    "vite": "^5.0.8",
    "typescript": "^5.3.3"
  }
}
```

## Success Criteria

- âœ… Scrapers successfully collect prices from at least 1 supermarket per country
- âœ… Daily cronjob runs automatically and logs results
- âœ… Database stores products, prices, and scrape history
- âœ… API provides endpoints for products, prices, and comparisons
- âœ… Dashboard displays price comparisons across countries
- âœ… Product matching works for common grocery items
- âœ… Error handling prevents crashes and logs failures
- âœ… System can be extended to add more supermarkets easily

## Future Enhancements (Post-MVP)

1. Add more supermarkets (2-3 per country)
2. Implement currency conversion for direct price comparison
3. Add user accounts and custom shopping lists
4. Price alert notifications
5. Mobile app with barcode scanner
6. Machine learning for better product matching
7. Price prediction and trend analysis
